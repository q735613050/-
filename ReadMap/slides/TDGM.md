# 摘要

生成模型是图模型与概率编程语言中概率推理的核心范例，最近由于神经网络在参数化方面的改进、以及基于梯度随机优化方面的进展，使得可以对高维数据进行跨模态建模。

本教程的前半部分，将全面介绍深度生成模型，包括生成对抗网络、变分自编码器以及自回归模型。对于每一个模型，我们都将深入探讨各自的概率公式、学习算法、以及与其他模型的关系。后半部分将演示一组具有代表性的推理任务，展示深度生成网络在其中的应用。最后，我们将讨论堂前领域面临的挑战，并展望未来的研究方向。

## 目录

第一部分：

- 生成模型的动机，以及与判别模型的对比
- 生成模型的定义、特征、估计密度、模拟数据、学习表示
- 传统生成模型方法，以及深度网络在参数化方面的作用
- 基于学习算法的生成模型分类，基于相似点的学习和无相似点的学习
- Likelihood-based学习实例
- 自回归模型
- 变分自编码器

第二部分：

- Likelihood-based学习实例（续）
- 规范化流模型
- Likelihood-free 学习实例
- 生成对抗网络
- 深度生成模型的实例
- 半监督学习
- 模仿学习
- 对抗样本
- 压缩感知
- 关于生成模型未来研究的主要挑战和展望。

原文链接：
https://ermongroup.github.io/generative-models/
