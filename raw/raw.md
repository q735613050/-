# 优秀资源

- [Von Luxburg U. A tutorial on spectral clustering[J]. Statistics and Computing, 2007, 17(4): 395-416.](../papers/ATutorialonSpectralClusterin.pdf)
- [Tian D, Kao J, Mansour H, et al. Graph spectral motion segmentation based on motion vanishing point analysis[C]. multimedia signal processing, 2015: 1-6.](../papers/GraphSpectralMotionSegmentationBased_on_MotionVanishingPointAnalysis.pdf)
- [Bach F R, Jordan M I. Learning Spectral Clustering[C]. neural information processing systems, 2004: 305-312.](../papers/learning-spectral-clustering.pdf)
- [Wang F, Zhang C. Label Propagation through Linear Neighborhoods[J]. IEEE Transactions on Knowledge and Data Engineering, 2008, 20(1): 55-67.](../papers/124_Label_Propagation_th.pdf)

---------

## 0 优秀的教程

### 让 DL 可解释: 贝叶斯深度学习教程

贝叶斯深度学习对于理解深度学习这个黑盒子能提供可解释性，在深度学习理论研究中这几年也是非常地热。机器学习专家 Andrew Gordon Wilson 在这个 PPT 教程详细讲述了模型选择、贝叶斯和频率的区别、贝叶斯推断、预测分布、Beta 分布、高斯过程、神经网络、以及作者最新提出的 [Bayesian GAN](../papers/BDL/6953-bayesian-gan.pdf)。

PPT 见 [BDL](../papers/BDL/bayesiandeeplearning.pdf)

### 带你领略深度生成模型全貌

本文为大家带来了斯坦福大学 PH.D Aditya Grover 同学的深度生成模型tutorial，希望对大家的学习有所帮助。

- [PPT](../papers/ijcai_ecai_tutorial.pdf)
- [简介](../slides/TDGM.md)

### Scikit-learn 作者之一可微分动态编程教程

法国 Inria Parietal，也是 scikit-learn 作者之一的论文关于结构性预测与注意力中的可微分动态编程。[PPT](../papers/diff_dp_icml.pdf) 内容详细描述了其中的细节.

论文: Differentiable Dynamic Programming for Structured Prediction and Attention

作者重点指出：Sparsity and backprop in CRF-like inference layers using max-smoothing, application in text + time series (NER, NMT, DTW).

### 2018 自然语言处理研究报告

由清华-中国工程院知识智能联合实验室AMiner发布:

- ppt: [2018 自然语言处理研究报告](../papers/2018自然语言处理研究报告.pdf)

### 如何搞明白深度学习的算法、理论与计算系统？

如何将深度学习等 AI 算法应用到实际场景里，不是一件容易的事情。 2016 年，卡耐基梅隆大学计算机科学院的终身教授邢波（Eric Xing）在匹兹堡创办了Petuum，他致力于创建一个平台，通过自定义的虚拟化和操作系统构建机器学习和深度学习应用程序，为企业提供所需的机器学习工具。结合 Petuum, 邢波教授在 7 月份深度学习夏令营分享了关于从统计机器学习视角理解深度学习的算法、理论与可扩展计算 (A Statistical Machine Learning Perspective of Deep Learning: Algorithm, Theory, Scalable Computing), 这一份 Slides 286页, 非常全面, 是一份结合学术研究和实际应用的详实参照学习材料，不可不看.

整个报告包括深度学习与图模型的基础知识、深度生成模型、计算机制三大部分。

- 第一部分着重讲述关于图模型、深度学习的基础、相似性区别和联合建模。结论部分点出图模型注重推理而深度学习注重学习表示。
- 第二部分讲述深度生成模型
- 第三部分 推断和学习以及分布式深度学习

邢波主页: http://www.cs.cmu.edu/~epxing/

### 帮你理解深度学习在智能对话系统中应用

- PPT: [NAACL2018 tutorial：Deep Learning for Conversational AI](../papers/naacl18-DeepLearning-for-ConversationalAI.pdf)
- [简介](../slides/DLAI.md)

参考链接：http://naacl2018.org/tutorial.html

### 人工智能、深度学习、神经网络、大数据备忘录

详见: [网站](https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463)

### 深度学习革命:基础，优化，正则

近年来，人们对深度学习 —— 广义上讲，一类基于多层神经网络的方法的兴趣大增。它在计算机视觉、自然语言处理、机器人和控制以及许多其他领域都非常有效。但是它对大多数人而言，是一个黑盒子。统计学家应该使用深度学习吗？这个“黑盒子”真的这么容易使用吗？统计学家是否有空间为深入学习“模型”的理解和/或进一步发展做出贡献？

本教程全面概述了一些最流行/最强大的深度学习方法，详细介绍了它们在各种场景下的应用，并解决了上述问题。演讲者有 Chris Manning和Ruslan Salakhutdinov。本教程将分为 4 个部分

- 深度学习简介
- 模型细节：优化、正则、可解释性
- 无监督学习：深度生成模型 玻尔兹曼机、GAN、VAE 等
- 卷积神经网络、循环神经网络、残差结构、注意力机制

论文下载: http://www.cs.cmu.edu/~rsalakhu/jsm2018.html

本站下载: [DL2018](https://github.com/q735613050/ReadMap/tree/master/papers/DL2018)

### 计算机图形学总览

计算机图形学是研究怎样利用计算机来显示、生成和处理图形的原理、方法和技术的一门学科。它的基本含义是使用计算机通过算法和程序在显示设备上构造图形。今日，清华大学计算机系 AMiner 团队联合中国工程科技知识中心，发布了一份计算计算机图像学的研究报告。总览计算机图像学的概念、技术、人才、会议、应用、趋势等，给领域内师生指明道路。 详细介绍见 [intros_CG](../slides/CG.md), 论文见 [CG](https://github.com/q735613050/ReadMap/tree/master/papers/CG).

### 深度生成模型最新发展脉络

本文整理自普林斯顿大学 Ryan P.Adams 教授的深度概率生成模型的教程，详细描述了生成模型的问题、算法以及应用。特别最后介绍联合图模型和神经网络，详细介绍了这两部结合的动机和如何考虑这两部分。

>作者简介：
Ryan P.Adams，普林斯顿大学教授，曾任职于多伦多大学、哈佛大学、Googel Brain等多所知名研究机构，并在哈佛大学期间，长期承担机器学习课程（CS181,CS281）的教学任务。

教程结构：

- 什么是生成模型
- 为什么选择深度生成模型
- 从数据中学习的生成模型算法
- 变分自编码器
- 联合图模型与神经网络

教程见: [A Tutorial on Deep Probabilistic Generative Models](../papers/ATutorial-on-DeepProbabilisticGenerativeModels.pdf)

### 何恺明 CVPR2018 关于视觉深度表示学习教程

在今年 CVPR 2018 上，刚获得 “TPAMI” 年轻研究员奖的 Facebook 的 Kaiming He 做了一个叫 “Learning Deep Representations for Visual Recognition” 的讲座。内容重点涵盖了他参与发明的ResNet/ResNeXt的细节结构以及一系列重要模型（包括 LeNet、AlexNet、GoogleNet）的回顾。整个讲座内容深入浅出，重要的技巧比如 Batch Normalization 也都有涵盖。这个教程非常适合对 ResNet 想深入了解的读者。详细内容见 [he](../papers/he.pdf)

----------------

## 1 标签传播

### 1.1 Zhu, 2002

- 论文: [Zhu X, Ghahramani Z.Learning from labeled and unlabeled data with label propagation. Pittsburgh: Carnegie Mellon University, 2002](../papers/LP.pdf)

## 2 强化学习

### 2.1 综述

- 论文: [A Survey of the Usages of Deep Learning in Natural Language Processing](../papers/ASurvey_of_the_Usages_of_DeepLearning-in-NaturalLanguageProcessing.pdf)
- 简述: [RLSuevey](../slides/RLSuevey.md)

## 3 自编码器

### 3.1 隐式自编码器

多伦多大学 Alireza Makhzani 博士在 Google Brain 的最新演讲，隐式自编码器 (IAE，Implicit Autoencoders).

>作者介绍：
Alireza Makhzani 博士目前是多伦多大学机器学习研究组的正式成员，于 2017 年在本校完成了电子与计算机工程博士学位，目前的研究工作主要集中在图像生成模型与半监督学习应用，以及深度强化学习算法。在博士期间，曾参加 Google Brain 团队实习，在那里完成了对抗自编码器的研发工作，并于 2016 年于 Google DeepMind 团队合作，为星际争霸2游戏研发深度强化学习算法。

本文介绍隐式自编码器（IAE），这是一种生成式自动编码器，其中的生成路径于识别路径都通过隐式表示完成了参数化。该方法使用两个生成对抗网络来定义隐式自编码器的损失函数，并基于最大似然学习推导出学习规则。使用隐式分布将允许该模型学习到更加具有表现力的后验和条件似然分布。学习条件似然分布将使得模型能捕获到数据的高级抽象信息。进而，作者证明了隐式自编码其可以解开全局和局部信息，并可以完成图像的确定性或随机重建工作。同时进一步表明了，隐式自编码器可以以无监督的方式从连续因子中得出离散的潜在变异因子，并进行聚类和半监督学习。

论文见: [Implicit Autoencoders](../papers/ImplicitAutoencoders.pdf)

### 3.2 变分自编码器

近几年来，变分自编码器（VAE，Variational Autoencoder）变得同 GAN 一样，成为生成模型种最流行的方法。本文整理了 CMU 大学 DL 课程中的 VAE 章节 PPT，希望能帮助大家更好的理解 VAE 原理.

课程介绍：

以深度神经网络为代表的深度学习系统越来越多的被应用于人工智任务中，从语言理解、语音、图像识别，到机器翻译、规划，甚至游戏和自动驾驶等任务。因此在许多高级研究领域中，机器学习知识已经成为先决条件，并在工业市场上供不应求。

在本课程中，我们将学习深度神经网络的基础知识，以及它们在各种AI任务中的应用，课程结束后，预计学生们能够较为熟练的将本课程中的方法应用于各种任务中，并未后续的研究打下基础。

课程地址：
https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Spring.2017/

PPT: [CMUVAE](../papers/lec12.vae.pdf)