# 阅读深度学习论文的新姿势

对于科研人员，尤其是研究生而言，阅读相关领域的最新论文十分重要，而每个月都有数百篇论文被发表，如何快速寻找以及阅读论文就变得至关重要。本文介绍了如何快速寻找与研究领域相关的论文，以及一些阅读论文的技巧。

作者｜Nityesh Agarwal

## 为什么阅读论文

Quora 上曾有人提问，如何判断自己适不适合研究机器学习，Andrew Ng（吴恩达，谷歌大脑创始人，百度 AI 小组前负责人）表示，任何人都有资格从事机器学习 。在完成一些与机器学习相关的课程后，更进一步，我们应该阅读研究论文，并且复现文中的结果。这表明阅读研究论文对于进一步了解该领域至关重要。

每个月都有数百篇论文被发表，任何希望深入某一领域的人都不能仅仅依靠“教程"来了解最近的研究热点，跟上节奏的唯一方法是养成阅读研究论文的习惯。

## 怎么阅读论文

下面介绍对阅读论文有帮助的一些资源：

### arXiv.org

arXiv 是一个论文预发布平台，许多研究人员会在会议或期刊正式发表之前就会论文传到这个平台。他们为什么要那样做？事实证明，写完论文不是科研的终点。将论文提交到某些科学期刊上发表是一个漫长的过程，因为有同行评审。而这对于机器学习等快速发展的领域来说真的是不可取的。

因此，研究人员将他们的论文发布在像 arXiv 这样的预发布平台，以便快速得到反馈。

### Arxiv Sanity Preserver

但是一打开 ArXiv，你会发现，实在有太多论文了，光是找到自己感兴趣的论文就要找很久，而 [Arxiv Sanity Preserver](http://www.arxiv-sanity.com/) 可以帮你迅速找到值得一看的文章，如最近一周 Twitter 上被提到最多的文章，根据你的阅读记录为你推荐的文章等。除此之外，它能够帮你找到与某篇文章相似的论文，也能够看到这个社区使用者关于某篇文章的讨论。更多功能有待自己去挖掘。

### Reddit 上的机器学习-WAYR

[WAYR](https://www.reddit.com/r/MachineLearning/comments/807ex4/d_machine_learning_wayr_what_are_you_reading_week/) 即 What Are You Reading 的缩写。它是 reddit 机器学习的一个主题，在这里，人们发布他们阅读的论文，并指出论文中有意思的地方。

正如我所说，每周在 arXiv 上发表的机器学习领域的研究论文数量非常多，一个人看不完,并且并不是所有论文都值得一读。而上述“论坛”能够帮你发现值得一读的论文。

### NewsLetter

NewsLetter 是追踪人工智能领域最新进展的最佳来源。订阅之后，每周都能收到本周与 AI 相关的最有趣的新闻，文章和研究论文。

下面列出几个比较好的来源：

- Jack Clark 的 [ImportAI](https://jack-clark.net/) 它除了提供最有趣的新闻，文章和研究论文之外，它还有一个名为「Tech Tales」的部分，包含基于过去一周活动的新 AI 相关短篇小说故事！
- Sam DeBrule 的[机器学习](https://jack-clark.net/)
- Nathan Benaich 的 [Nathan.ai](https://www.getrevue.co/profile/nathanbenaich).
前两个 NewsLetter 都是每周一次，而这是一份季刊。因此，您每 3 个月会收到一封长电子邮件，其中总结了过去 3 个月内该领域最有趣的发展。
- Denny Britz 的 [The Wild Week in AI](https://www.getrevue.co/profile/wildml)

#### 推特上的 “AI人”（翻墙食用更佳）

另一个可以跟上最佳和最新领域的好方法就是 Follow 着 Twitter 上着名的研究人员。比如说：

- Michael Nielsen
- Andrej Karpathy
- Francois Chollet
- Yann LeCun
- Chris Olah
- Jack Clark
- Ian Goodfellow
- Jeff Dean
- OpenAI
- [专知网站](http://www.zhuanzhi.ai) 是一个国内的查找人工智能最新论文的网站, 使用细则见[这](https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247491606&idx=5&sn=dddef785f5ca3482698de490e9e8e358&scene=21#wechat_redirect)。

## 那么问题来了，怎么读论文？

没错，这是一个更为关键的问题。

首先要确保您了解机器学习和深度学习的基础知识 - 如反向传播，正则化以及 ConvNets，RNN 和 LSTM。学习这些基础知识不用读提出他们的原始论文，毕竟网络上已经有很多对它们的解读和介绍，可以使我们快速理解概念。

打完基础之后，你才应该去找提出它们的原始论文。这样，您就可以专注于研究论文的结构。由于您已经非常熟悉这个想法，因此您不必过于担心理解不了它。

由 Alex Krizhevsky，Ilya Sutskever 和 Geoffrey Hinton 撰写，题为 ImageNet Classification with Deep Convolutional Networks，本文被认为是该领域最具影响力的论文之一。它描述了作者如何使用 CNN（实为AlexNet）赢得 ImageNet 大规模视觉识别挑战赛（ILSVRC）2012。
因此, 从 AlexNet 开始阅读是一个不错的选择。读完该文后，您可以查看与 CNN 相关的其他此类开创性论文，或者转移到您感兴趣的其他架构（RNN，LSTM，GAN）。

原文链接：
https://towardsdatascience.com/getting-started-with-reading-deep-learning-research-papers-the-why-and-the-how-dfd1ac15dbc0
